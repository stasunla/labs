{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d1afdc-815d-48dc-bc9d-4f82c8674f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546/546 [==============================] - 332s 603ms/step - loss: 0.6592 - accuracy: 0.6069 - val_loss: 0.6407 - val_accuracy: 0.6382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264c442db88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Загрузка данных из pickle файлов\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "# Нормализация данных\n",
    "X = X/255.0\n",
    "\n",
    "# Преобразование в массивы NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Создание модели\n",
    "model = Sequential()\n",
    "\n",
    "# Добавление входного слоя\n",
    "model.add(Input(shape=X.shape[1:]))\n",
    "\n",
    "# Добавление сверточных слоев\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Выравнивание данных перед подачей их на полносвязный слой\n",
    "model.add(Flatten())\n",
    "\n",
    "# Полносвязные слои\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Сигмоидная функция активации для бинарной классификации\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X, y, batch_size=32, epochs=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26debce-33ca-4818-933a-a9387805b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-64-nodes-0-dense-1710565040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evgen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.5619 - loss: 0.6745 - val_accuracy: 0.6319 - val_loss: 0.6402\n",
      "Epoch 2/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6996 - loss: 0.5801 - val_accuracy: 0.7496 - val_loss: 0.5146\n",
      "Epoch 3/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.7558 - loss: 0.5083 - val_accuracy: 0.7523 - val_loss: 0.5042\n",
      "Epoch 4/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.7784 - loss: 0.4669 - val_accuracy: 0.7803 - val_loss: 0.4623\n",
      "Epoch 5/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.7978 - loss: 0.4353 - val_accuracy: 0.7849 - val_loss: 0.4547\n",
      "Epoch 6/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8250 - loss: 0.3978 - val_accuracy: 0.7980 - val_loss: 0.4369\n",
      "Epoch 7/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8324 - loss: 0.3678 - val_accuracy: 0.7934 - val_loss: 0.4544\n",
      "Epoch 8/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8485 - loss: 0.3356 - val_accuracy: 0.8013 - val_loss: 0.4394\n",
      "Epoch 9/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8612 - loss: 0.3154 - val_accuracy: 0.8024 - val_loss: 0.4395\n",
      "Epoch 10/10\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.8777 - loss: 0.2886 - val_accuracy: 0.8089 - val_loss: 0.4309\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af60612d-1d63-4c49-a02d-166a82647699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]  # будет использовать это для преобразования числа предсказания в строковое значение\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2101fbd0-35e9-40cd-9d97-6c321fd441cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"64x3-CNN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b5e23a-b5f4-40df-8087-a17785998f94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "[[0.]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.keras\")\n",
    "\n",
    "prediction = model.predict([prepare('31.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934d798-0f31-4479-9739-149682e4a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
